\section{Testing a GPU Port of a Numerical Application}

The general problem is to test whether changes to a numerical application generate different answers.
Since these are typically floating point applications, the meaning of \emph{different} depends on the precision needed.
Since all processors now use IEEE floating point arithmetic\cite{goldberg.cs.91}, many programmers expect that moving a program to another processor or changing optimiziations should produce exactly the same answer.
Even with the same floating point representation, different compilers and libraries (even on the same processor) can give different results, for many well-known reasons, including:
\begin{itemize}
\item Different optimizations (changing a/5.0 into a*0.2), or
\item Presence or absence of FMA operations on the original or new processor, or different FMA association ($(a*b)+(c*d)$ treated as $\textit{fma}(a,b,c*d)$ or $\textit{fma}(c,d,a*b)$).
\item Different transcendentals (different implementations of exp, sin, sqrt), or
\item For parallel programs, different order of operations, specifically for reductions (sums).
\end{itemize}
A good testing scheme must test for significant differences, but allow for and ignore insignificant differences, as long as the final result is accurate.

The test should determine not only that there are differences, but also identify where the differences are introduced.
Thus, the testing process should compare intermediate results as well as the final result.
There is also the problem of what to do when an error is found.
It could be treated the same as a floating point exception, giving an error message and terminating the program.
Another option is to report the error and continue, perhaps allowing identification of more errors, with perhaps a limit on the number of errors reported.
A third option is to replace the erroneous values with the known correct values before continuing.

The specific problem addressed here is to test whether porting a numerical application to a GPU-accelerated system generates different answers than the host execution.
When debugging OpenACC programs targeting GPUs, we have additional problems as well as an important advantage.
The problems include using two different processors in the same application, and managing data traffic and coherence between the system memory and the GPU device memory.
The important advantage is that we have two processors, so we can create the reference values on the CPU while the GPU is executing, and we have separate memories for the CPU and GPU, so we have a place to store the reference values and the test values.
Many of the problems that arise when programming GPUs with OpenACC have to do with managing the separate memories (stale data on the GPU or the CPU), or dealing with all the problems of porting to a new processor with part of the program still running on the old processor.

